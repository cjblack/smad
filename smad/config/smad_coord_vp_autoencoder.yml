cfg_name: smad_coord_vp_autoencoder
model_name: LstmAutoencoderAnomaly
module: smad.models.autoencoders
params:
  model:
    hidden_size: 128
    input_size: 8
    latent_dim: 64
    num_encoder_layers: 1
    num_decoder_layers: 1
    pooling: False
    dropout: 0.0
    skip_connections: False
  training:
    batch_size: 32
    criterion: MSELoss
    epochs: 200
    learning_rate: 0.0001
    optimizer: Adam
    autoregressive_ft:
      epochs: 0
      learning_rate: 0.00001
